{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_fashion_mnist3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "x4v1Xnp2f8B9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "6089lVOLf8B_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras # Importing Keras\n",
        "from keras import backend as K # Importing Keras backend (by default it is Tensorflow)\n",
        "from keras.datasets import fashion_mnist # Import the fashion-mnist dataset\n",
        "from keras.layers import Input, Conv2D, Dense, Dropout, Flatten, MaxPool2D, BatchNormalization # Layers to be used for building our model\n",
        "from keras.models import Model # The class used to create a model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils # Utilities to manipulate numpy arrays\n",
        "from tensorflow import set_random_seed # Used for reproducible experiments\n",
        "from keras.preprocessing.image import ImageDataGenerator # Used for image dataset handling\n",
        "\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iXjh3U0Nf8CF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data manipulation\n",
        "\n",
        "**Task**: Given an image decide the type of clothing\n",
        "\n",
        "- The data are Grayscale images of size 28x28\n",
        "- We will use a CNN to classify them\n",
        "- The values of the inputs are in [0, 255] so we normalize them to [0, 1]"
      ]
    },
    {
      "metadata": {
        "id": "VBIMcJGsf8CG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "classes = 10\n",
        "epochs = 100\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "        \n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(input_shape)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, classes)\n",
        "y_test = keras.utils.to_categorical(y_test, classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1hgyun80f8CJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plotting results"
      ]
    },
    {
      "metadata": {
        "id": "oW4h9EJ2f8CJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_history(hs, epochs, metric):\n",
        "    plt.clf()\n",
        "    plt.rcParams['figure.figsize'] = [10, 5]\n",
        "    plt.rcParams['font.size'] = 16\n",
        "    for label in hs:\n",
        "        plt.plot(hs[label].history[metric], label='{0:s} train {1:s}'.format(label, metric))\n",
        "        plt.plot(hs[label].history['val_{0:s}'.format(metric)], label='{0:s} validation {1:s}'.format(label, metric))\n",
        "    x_ticks = np.arange(0, epochs + 1)\n",
        "    x_ticks [0] += 1\n",
        "    plt.xticks(x_ticks)\n",
        "    plt.ylim((0, 1))\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss' if metric=='loss' else 'Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qk4w10wUf8CM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cleaning up"
      ]
    },
    {
      "metadata": {
        "id": "Y9DDLBBAf8CM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_up(model):\n",
        "    K.clear_session()\n",
        "    del model\n",
        "    gc.collect()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "16OIddjnjxIg"
      },
      "cell_type": "markdown",
      "source": [
        "### Model creation"
      ]
    },
    {
      "metadata": {
        "id": "C8jXKxfqf8CP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "        optimizer,\n",
        "        epochs=100,\n",
        "        batch_size=128,\n",
        "        conv_layers=2,\n",
        "        conv_activation='relu',\n",
        "        conv_dropout=False,\n",
        "        output_activation='softmax'):\n",
        "    \n",
        "    np.random.seed(1402) # Define the seed for numpy to have reproducible experiments.\n",
        "    set_random_seed(1981) # Define the seed for Tensorflow to have reproducible experiments.\n",
        "    \n",
        "    # Define the input layer.\n",
        "    input = Input(\n",
        "        shape=input_shape,\n",
        "        name='Input'\n",
        "    )\n",
        "\n",
        "    x = input\n",
        "    \n",
        "    # Define the convolutional layers.\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(1, 1),\n",
        "        padding='same',\n",
        "        dilation_rate=(1, 1),\n",
        "        activation=conv_activation,\n",
        "        name='Conv2D-1.1'\n",
        "    )(x)\n",
        "    x = Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(1, 1),\n",
        "        padding='same',\n",
        "        dilation_rate=(1, 1),\n",
        "        activation=conv_activation,\n",
        "        name='Conv2D-1.2'\n",
        "    )(x)\n",
        "    x = MaxPool2D(\n",
        "        pool_size=(2, 2),\n",
        "        strides=(2, 2),\n",
        "        padding='same',\n",
        "        name='MaxPool2D-1'\n",
        "    )(x)\n",
        "    x = Dropout(\n",
        "        rate=0.1,\n",
        "        name='Dropout-1'\n",
        "    )(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(1, 1),\n",
        "        padding='same',\n",
        "        dilation_rate=(1, 1),\n",
        "        activation=conv_activation,\n",
        "        name='Conv2D-2.1'\n",
        "    )(x)\n",
        "    x = Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(1, 1),\n",
        "        padding='same',\n",
        "        dilation_rate=(1, 1),\n",
        "        activation=conv_activation,\n",
        "        name='Conv2D-2.2'\n",
        "    )(x)\n",
        "    x = MaxPool2D(\n",
        "        pool_size=(2, 2),\n",
        "        strides=(2, 2),\n",
        "        padding='same',\n",
        "        name='MaxPool2D-2'\n",
        "    )(x)\n",
        "\n",
        "    x = Dropout(\n",
        "        rate=0.4,\n",
        "        name='Dropout-2'\n",
        "    )(x)\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(\n",
        "      filters=128,\n",
        "      kernel_size=(3, 3),\n",
        "      strides=(1, 1),\n",
        "      padding='same',\n",
        "      dilation_rate=(1, 1),\n",
        "      activation=conv_activation,\n",
        "      name='Conv2D-3.1'\n",
        "    )(x)\n",
        "    x = Conv2D(\n",
        "        filters=256,\n",
        "        kernel_size=(3, 3),\n",
        "        strides=(1, 1),\n",
        "        padding='same',\n",
        "        dilation_rate=(1, 1),\n",
        "        activation=conv_activation,\n",
        "        name='Conv2D-3.2'\n",
        "    )(x)\n",
        "    x = MaxPool2D(\n",
        "        pool_size=(2, 2),\n",
        "        strides=(2, 2),\n",
        "        padding='same',\n",
        "        name='MaxPool2D-3'\n",
        "    )(x)\n",
        "    x = Dropout(\n",
        "        rate=0.5,\n",
        "        name='Dropout-3'\n",
        "    )(x)\n",
        "    \n",
        "    # Flatten the convolved images so as to input them to a Dense Layer\n",
        "    x = Flatten(name='Flatten')(x)\n",
        "    x = Dense(\n",
        "          units=256,\n",
        "          activation='relu',\n",
        "          name='Dense-1'\n",
        "    )(x)\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    # Define the output layer.\n",
        "    output = Dense(\n",
        "        units=classes,\n",
        "        activation=output_activation,\n",
        "        name='Output'\n",
        "    )(x)\n",
        "\n",
        "     # Define the model and train it.\n",
        "    model = Model(inputs=input, outputs=output)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    hs = model.fit( \n",
        "      x=x_train,\n",
        "      y=y_train,\n",
        "      validation_split=0.1, # use 10% of the training data as validation data\n",
        "      epochs=epochs,\n",
        "      verbose=1,\n",
        "      batch_size=batch_size\n",
        "    )\n",
        "    \n",
        "    print('Finished training.')\n",
        "    print('------------------')\n",
        "    model.summary() # Print a description of the model.\n",
        "    return model, hs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tnhNc2sOj5f8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our model initialization"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "9mhWK6ftf8CS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Using Adam\n",
        "optimizer = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# 3 Convolutional Layers\n",
        "conv_no_drop_model_adam, conv_no_drop_hs_adam = train_model(\n",
        "    optimizer=optimizer,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    conv_layers=3,\n",
        "    conv_activation='relu',\n",
        "    conv_dropout=False,\n",
        "    output_activation='softmax'\n",
        ")\n",
        "\n",
        "# Evaluate on test data and show all the results.\n",
        "conv_no_drop_eval_adam = conv_no_drop_model_adam.evaluate(\n",
        "    x_test,\n",
        "    y_test,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "clean_up(model=conv_no_drop_model_adam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ItZ8t3RDf8CW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Results"
      ]
    },
    {
      "metadata": {
        "id": "7vwt3T2df8CW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Train Loss     : {0:.5f}\".format(conv_no_drop_hs_adam.history['loss'][-1]))\n",
        "print(\"Validation Loss: {0:.5f}\".format(conv_no_drop_hs_adam.history['val_loss'][-1]))\n",
        "print(\"Test Loss      : {0:.5f}\".format(conv_no_drop_eval_adam[0]))\n",
        "print(\"---\")\n",
        "print(\"Train Accuracy     : {0:.5f}\".format(conv_no_drop_hs_adam.history['acc'][-1]))\n",
        "print(\"Validation Accuracy: {0:.5f}\".format(conv_no_drop_hs_adam.history['val_acc'][-1]))\n",
        "print(\"Test Accuracy      : {0:.5f}\".format(conv_no_drop_eval_adam[1]))\n",
        "\n",
        "\n",
        "# Plot train and validation error per epoch.\n",
        "plot_history(hs={'Conv': conv_no_drop_hs_adam}, epochs=epochs, metric='loss')\n",
        "plot_history(hs={'Conv': conv_no_drop_hs_adam}, epochs=epochs, metric='acc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "96pYf8a2f8Ch",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "exit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D0z5oHtqf8Ck",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}